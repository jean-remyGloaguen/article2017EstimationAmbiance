\documentclass[twocolumn,a4paper,10pt]{article}

\input{../packageEN}
\input{../packageStyle}

\title{Estimation of the traffic sound level from measurements made in an urban environment}

\author{
    Jean-Rémy GLOAGUEN\\
    Arnaud Can\\
    LAE\\
    Ifsttar\\
    jean-remy.gloaguen@ifsttar.fr
  \and
    Mathieu Lagrange\\
	Jean-François Petiot \\
    LS2N\\
    Central School of Nantes\\
}
\date{}
\begin{document}

\maketitle

\section*{Abstract}

\section{Introduction}

Road traffic noise is one of the main annoyance perceived by urban dwellers and a major societal issue because too long exposures to high sound levels can generate health problems  \cite{who_burden_2017}.  Accordingly, the European Directive 2002/EC/49 \cite{directive} has been developed to determine the exposuer of the populations. Cities with a population of more than 100 000 must produce road traffic noise maps. These maps come from a simulation process resulting from the estimation of the traffic density on the main roads and calculating sound propagation. The maps express $L_ {DEN}$ and $L_N$, respectively, \textit{Day-Evening-Night} and \textit{Night} equivalent A-weighted sound levels. These maps make it possible to estimate the number of city dwellers exposed to highly annoyant noise levels and to draw up action plans to reduce them. However, these maps introduce lot of uncertainty generated by the numerical tools \cite{van_leeuwen_noise_2015}, by the different calculation methodologies used \cite{leroy_uncertainty_2010}\cite{garg_critical_2014} or even by the calculation procedure of the number of inhabitants exposed to noise \cite{king_implementation_2011}. In addition, the usual road traffic noise maps are static, aggregating the exposure on the two indicators $L_{DEN}$ and $L_N$, thus ignoring the sound levels evolution throughout the day. Since the creation of road traffic noise maps entails long data collection and calculation times, the use of measurements could facilitate their updating or even the generation of dynamic maps \cite{wei_dynamic_2016}. These measurements can be performed at fixed stations spread all over the cities \cite{Mioduszewski} \cite{mietlicki2012innovative}, which allow to get the long-term evolution of the traffic noise levels, or can be performed with  mobile stations \cite{can_exploring_2012} \cite{manvell2004sadmam} covering a larger area with fewer sensors but also sparse time perdiods. The clustering between mobile and fixed measurements have been studied in \cite{can_measurement_2014}.

Currently, we are seeing the diffusion of sensor networks in cities for multiple applications (air quality assessment, measurement of meteorological parameters), including assessment of urban noise levels. Various projects exist to study the establishment and feasibility of such installations as the DYNAMAP \cite{dynamap_2016} project. It focuses on sensor installations on specific roads in all cities of Milan and Rome \cite{bellucci_life_2017}. In a similar way, but reduced to few neighborhoods, the CENSE project\footnote{\url{http://cense.ifsttar.fr/}} \cite{} plains to combine \textit{in situ} observations, from a sensor network, and numerical data, from noise modeling, by using data assimilation techniques.

If these installations, from their measurements, allow to have a more precise evaluation of the traffic noise in cities than the simulated maps, the issue of the correct estimation from measurement of the traffic sound level is still unsolved \cite{Mioduszewski}. Indeed, the urban sound environment is a complex environment gathering lots of different sounds both from a temporal and a frequency point of view (car passages, voices, bird's whistles, car horn \dots) that can overlap. In consequence, the traffic sound level estimation is not trivial task. 

Many works have been focused on the detection  \cite{heittola_sound_2011} or on recognition \cite{defreville_automatic_2006} task of environmental sounds. These methods use a two step process : describe the audio files with a set of features (Spectrum Gravity Spectrum, harmonicity, Mel-Frequency Cepstral Coefficient \dots) and classified them with the help of classifiers (Support Vector Machines, Gaussian Mixture Models, Hidden Markov Model, Artifical Neural Networks). A description of there features and classifiers can be found on \cite{cowling_comparison_2003} and their application can be found in \cite{shen_environmental_2012}, \cite{beritelli_pattern_2008}, \cite{couvreur_automatic_2004}.
However, many of these results in the detection or recognition tasks, do not address the overlap of environmental sounds in an urban context. Although in some places, near major roads or ring roads, traffic is predominant on all other sound sources, there are many places where there is little traffic and overlaps with other sound sources. The only detection of the traffic component does not make it possible to determine precisely its noise level. In consequence, to be effective on all the different sound environments, it seems more suited to consider the issue as the one of blind source separation.

One of the first and the most widely used techniques is the Independent Component Analysis \cite{comon_independent_1994}. The principle is to decompose $N$ recorded signals in a sum of $P$ independent sound sources weighted by linear relations. This method is most of all suited for the 'cocktail party' issue where one tries to capture a signal among noise.  However, ICA is limited to only over determined cases ($N > P$). Furthermore, if it is suited for indoor environments where the number of sound sources is constant, it can not be fitted for an outdoor environment where the number of sources is unknown and variable and, moreover, it would be necessary to install multiples sensors on one point to realize the source separation which is not feasible. A second method is Non-negative Matrix Factorization (NMF) \cite{lee_learning_1999} which consists in approximate the non-negative spectrogram of an audio file from the product of two matrices. It has been widely used in the audio domain, \cite{smaragdis_non-negative_2003} \cite{wilson_speech_2008} \cite{mesaros_sound_2015}, and has already been employed for the source separation task of a monaural signal included speech and musical contents  \cite{wang_musical_2005} \cite{wilson_speech_2008}. This method has the advantage to easily deals with the overlap of the sound sources. For the environmental sounds, the method has been used for geo-localisation and classification of the sound environment like in \cite{kumar_audio_2016} where NMF allows to classify the audio files according to the 10 cities where they have been recorded. For the source separation, it has been used by Innami and Kasai in the unsupervised case. They proposed a source separation in two step  by separating the sound background from the events first and by separating the events between them. The audio files tested results of a simulation process where a sound background (river or wind) are adding to two sound events (school chime, announcement, frog croaking, dog barging and bell ringing). If the method proposed is interesting, the main issue here is the small size of the database (only 9 sounds) on which the algorithms are tested while some sounds (frog and river) are not representative of sounds that can be found in cities.

Our study proposed to applied Non-Negative Matrix Factorization on simulated sound mixtures to succeed on the estimation of the traffic sound level. The use of simulated sound mixtures is necessary as it offers a full control on the design of the scenes and the knowledge of the exact contribution of the traffic component what recordings do not allow. Part \ref{part:nmf} details the technical aspect of NMF. Part \ref{part:protocol} is focused on the experimental protocol set up. Then part \ref{part:results} reveals the results obtained during the parametric study. 

\section{Non-negative Matrix Factorization}\label{part:nmf}
\subsection{Supervised NMF}
Non-negative Matrix Factorization (NMF) is an approximation method introduced by Lee and Seung, \cite{lee_learning_1999}, which estimates the spectrogram (get from a Short-Term Fourier Transform) of an audio file, $\mathbf{V}$, $\in \mathbb{R}^+_{F \times N}$ as : 

\begin{equation}\label{eq:nmf}
\mathbf{V} = \mathbf{\tilde{V}} \approx \mathbf{WH}
\end{equation}

where $\mathbf{W} \in \mathbb{R}^+_{F \times K}$ is the \textit{basis} matrix composed of audio spectrum and $\mathbf{H} \in \mathbb{R}^+_{K \times N}$ is the \textit{activation} matrix which summarizes the temporal evolution of each element of $\mathbf{W}$ (fig.  \ref{fig:example_NMF}). 

\begin{figure}[hbtp]
\centering
\includegraphics[width=0.9\linewidth]{../image/illustration_NMF.PNG}
\caption{Example of a simple NMF  for a musical content \cite{bertin_les_2009}}
\label{fig:example_NMF}
\end{figure}

The choice of the dimensions is done in a such way that $F\times K + K \times N < F \times N$. To estimate the quality of the approximation, an objective function is used 

\begin{equation}\label{eq:min-D-WH}
\underset{\mathbf{H} \geq 0, \mathbf{W} \geq 0}{\min} D\left(\mathbf{V} \vert \vert \mathbf{\tilde{V}}\right)
\end{equation}

The operator $D(x\vert y)$ is a divergence calculation such as 
\begin{equation}
D\left(\textbf{V} \vert\vert \mathbf{\tilde{V}} \right) = \sum_{f = 1}^{F} \sum_{n = 1}^{N} d_{\beta} 
\left(\textbf{V}_{fn} \vert \left[ \textbf{WH} \right]_{fn} \right)
\end{equation} 

and usually belongs to the $\beta-$divergence class \cite{fevotte_nonnegative_2009} in which the well known Euclidean distance (eq. \ref{eq:def_distEUC}) and the Kullback-Leibler divergence (eq. \ref{eq:def_divKL}) belong

\begin{subequations}\label{eq:divBetaGenerale}
\begin{numcases}{d_{\beta}(x\vert y) =}
    \frac{1}{2}(x-y)^2, & $\beta = 2$, \label{eq:def_distEUC}\\
    x\log \dfrac{x}{y} - x + y, & $\beta = 1$.\label{eq:def_divKL}
\end{numcases}
\end{subequations}

The prior knowledges on the content can be adjust with the add of constraints (like the smoothness or the sparsness criteria \cite{virtanen_monaural_2007}) in the objective function (equation (\ref{eq:min-D-WH})).

Multiple methods exist to solve the minimization problem (\ref{eq:min-D-WH}) (Alternating Least Square Method \cite{cichocki_regularized_2007}, Projected Gradient \cite{lin_projected_2007} \dots). Here, the multiplicative update is the chosen method \cite{lee_algorithms_2000} as it assures to have a non-negative results where the convergence of the results have been proved \cite{fevotte_algorithms_2011}. The minimization problem (\ref{eq:min-D-WH}) is solved iteratively. NMF is employed here in the supervised case: the \textit{dictionary} is already known as in the urban environments, a lot of different sound sources present are known and their spectrum can be obtained. The \textit{basis} are the unknown to find. In the first iteration, $\mathbf{H}$ is initialized randomly, then it is updated by the generic  algorithm 

\begin{equation}
\textbf{H}^{(i+1)} \leftarrow \textbf{H}^{(i)}.\left(\frac{\textbf{W}^T \left[\left(\textbf{WH}^{(i)} \right)^{(\beta-2)}.\textbf{V} \right]}{\textbf{W}^T \left[\textbf{WH}^{(i)} \right]^{(\beta-1)}}\right)^{\gamma(\beta)}
\end{equation}

with $\gamma(\beta) = \frac{1}{2-\beta},$ for $\beta < 1$, $ \gamma(\beta) = 1$, for $\beta \in \left[1,2\right]$ and $\gamma(\beta) = \frac{1}{\beta-1}$ for $\beta > 2$. The product $A.B$ and $A/B$ symbolized the Hadamard product and ratio. The source separation is made after $I$ iterations either by extracting the dictionary and basis elements related to the traffic

\begin{equation}\label{eq:separationExtraction}
\mathbf{\tilde{V}}_{traffic} = \left[ \mathbf{WH} \right]_{traffic}
\end{equation}

%or by generating a soft mask, $\mathbf{M_s}$, 
% 
%\begin{equation} \label{eq:definitionMask}
%\mathbf{M_s} = \frac{\left[\mathbf{W} \mathbf{H}\right]_{traffic}}{\mathbf{W H}}, 
%\end{equation}
%
%which allows to determine the spectrogram of the traffic component, $ \mathbf{\tilde{V}}_{traffic}$
%
%\begin{equation}\label{eq:separation}
%\mathbf{\tilde{V}}_{traffic} = \mathbf{M_s}.\mathbf{V}.
%\end{equation}

\subsection{Semi-supervised NMF}

One of the main issue with the supervised approach is this is not always adapted to different sound environments. Because in the supervised case, the fixed dictionary has to sum up all the sound sources present in the different sound environment. In consequence, as the dictionary dimension is limited and cannot include all the urban sounds, to offer more flexibility, semi-supervised NMF has been proposed \cite{lee_semi-supervised_2010}. This method consists in composing the \textit{dictionary} with a fixed part $\mathbf{W_s} \in \mathbb{R}^+_{F\times K}$ (composed here of traffic audio spectrum) and with a mobile part, $\mathbf{W_r} \in \mathbb{R}^+_{F\times J}$ that is updated. The aim is to include in $\mathbf{W_r}$ the element that are not related with the traffic. The problem (\ref{eq:nmf}) become

\begin{equation}
\mathbf{V} \approx \mathbf{W_s H_s}+ \mathbf{W_r H_r}
\end{equation}

In a similar way as to solve the equation \ref{eq:min-D-WH}, $\mathbf{W_r}$, $\mathbf{H_r}$ and $\mathbf{H_s}$ are successively updated with the relations (\ref{eq:WH-SSupdate}): 

{\scriptsize
\begin{subequations}\label{eq:WH-SSupdate}
\begin{align}
\mathbf{W_r}^{(i+1)} &\leftarrow \mathbf{W_r}^{(i)}.\left(\frac{\left[\left(\mathbf{W_r H_r}^{(i)} \right)^{(\beta-2)}.\mathbf{V} \right]\mathbf{H_r}^T}{\left(\mathbf{W_r H_r}^{(i)} \right)^{(\beta-1)}\mathbf{H_r}^T}\right)^{\gamma(\beta)}\label{eq:W_r_SS}\\
\mathbf{H_r}^{(i+1)} &\leftarrow \mathbf{H_r}^{(i)}.\left(\frac{\mathbf{W_r}^T \left[\left(\mathbf{W_r H_r}^{(i)} \right)^{(\beta-2)}.\mathbf{V} \right]}{\mathbf{W_r}^T \left(\mathbf{W_r H_r}^{(i)} \right)^{(\beta-1)}}\right)^{\gamma(\beta)}\label{eq:H_r_SS}\\
\mathbf{H_s}^{(i+1)} &\leftarrow \mathbf{H_s}^{(i)}.\left(\frac{\mathbf{W_s}^T \left[\left(\mathbf{W_s H_s}^{(i)} \right)^{(\beta-2)}.\mathbf{V} \right]}{\mathbf{W_s}^T \left(\mathbf{W_s H_s}^{(i)} \right)^{(\beta-1)}}\right)^{\gamma(\beta)}\label{eq:H_s_SS}
\end{align}
\end{subequations}}

This approach has been used TO COMPLETE.

\section{Experimental protocol}\label{part:protocol}

To assess the performance of NMF, simulated sound mixtures are used as it offers a controlled framework to design specific sound environments where all the traffic component is known. The estimation of the traffic sound level can be compare to an exact solution. 

\subsection{Environmental sound scene corpus}

A first corpus is design with the \textit{simScene} software\footnote{Open-source project available at: \url{https://bitbucket.org/mlagrange/simscene}}. \textit{simScene} \cite{rossignol_simscene:_2015} is a simulator that creates sound mixtures in a .wav format by superposing audio samples that come from an isolated sound database. This database is divided in two categories: the \textit{event} category which are the brief sounds (from 1 to 20 seconds) that are considered as salient whereas all the sounds that are of long duration and whose acoustic properties do not vary with respect to time belong to the \textit{background} category. Inside each category, the sound samples are grouped in sound classes (\textit{bird, car, foot steps} \dots), each of them being composed of multiples samples (bird01.wav, bird02.wav \dots).

The software allows the user to control some parameters as the number of events of each class that appears in the mixture, the elapsed time between each sample of a same class or the presence of a fade in and a fade out \dots. Each parameter is completed with a standard deviation that may brings some random behavior between the scenes. Furthermore, with the global scene mixture, an audio for each sound class presented in the scene can be generated that allow to know its exact contribution and a text file is created that summarizes the time presence of all the events.\\

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{../image/exampleSimScene2.pdf} 
\label{fig:exampleSimScene}
\caption{Example of a sound mixture composed of 3 sound classes (car, bird, car horn)}
\end{figure}

With this software, a sound database has been built including 245 sound event samples (with the sound classes \textit{ringing bell, birds, sweeping bropom, car horn, car passages, hammer, drill, coughing, barking dog, rolling suitcase, closing door, plane, siren, footstep, storm, street noise, train, tramway, truck and voice}) and 154 sound background samples (\textit{birds, construction site noise, crowd, park, rain, children playing in schoolyard, constant traffci noise, ventilation, wind}). The sound class \textit{car passages} comes from recordings of 4 cars made on the Ifsttar's runway on different speeds with multiple gear ratio \cite{gloaguen_creation_2017}. The other audio files have been found online (\textit{freesound.org}) and with the help of the \textit{UrbanSound8k} database \cite{salamon_dataset_nodate}. A sound mixture corpus is designed composed of 6 sub-corpus of 25 30 seconds audio files ($N = 25$). Each sub-corpus is characterized by a specific generic sound class : \textit{alert} (car horn, siren), \textit{animals} (barking dog , whistling birds), \textit{climate} (wind, rain), \textit{humans} (crowd noise and voice), \textit{mechanics} (different metallic and construction site noise) and \textit{transportation} (train, tramway and plane). In each file, traffic component is present as sound background and event and is mixed with on or multiple sound classes. The sound classes that are not related to the traffic component are summed up as the \textit{perturbator} (n'existe pas comme terme, disruptive à la place ?) class. To test different scenarios, each audio file is duplicated with the traffic sound level of the entire sound mixture, $L_{p,traffic}$, fixed to a specific level according to the sound level of the \textit{perturbator} class, $L_{p,perturbator}$ following the relation (\ref{eq:tpr}). 

\begin{equation}\label{eq:tpr}
TPR = L_{p,traffic}-L_{p,perturbator}
\end{equation}

with the \textit{Traffic Perturbator Ratio} $TPR = \left[-12, -6, 0, 6, 12\right]$. When $TPR = -12$, the traffic component is then less present than when $TPR = 12$ where it is predominant on the \textit{perturbator} class. The 1 second equivalent sound pressure level, $p_{1s,traffic}$, is too calculated (figure \ref{fig:exampleScene}). Finally, the number of scenes designed is 750 (6 sub-corpus $\times$ 25 scenes $\times$  5 TPR values). 

\begin{figure*}
\centering
   \begin{minipage}[c]{.32\linewidth}
      \includegraphics[width =\linewidth]{../image/spectrogramExample.pdf} 
   \end{minipage} 
   \begin{minipage}[c]{.32\linewidth}
      \includegraphics[width =\linewidth]{../image/animals_10-pianoRoll.png} 
   \end{minipage} 
   \begin{minipage}[c]{.32\linewidth}
      \includegraphics[width =\linewidth]{../image/evolutionLpExample.pdf} 

   \end{minipage}
\caption{Example of a scene of the \textit{animals} sub corpus. Spectrogram (on left), \textit{Piano Roll} of the different sound classes (on the middle) and 1-s equivalent sound level of the traffic, $Lp_{1s,traffic}$ and of the global sound mixture, $Lp_{1s,global}$(on right)}
\label{fig:exampleScene}
\end{figure*}

\subsection{Experiment}

The experiment consists in applied NMF on the environmental sound corpus to estimate the sound level of the traffic road. This method is compared to a simple approach which is a low-frequency filter. This method considers, as the traffic component is mostly composed of low-frequencies, that the sound level can be calculated from the band-pass filter. Similarly, for NMF, the low-pass filter is applied on $\mathbf{V}_{f_c}$ and $\mathbf{W}_{f_c}$ with the aim to focus the reconstruction of the signal on the frequencies where the traffic components are. The figure \ref{fig:block_diagram_protocol} summarizes the different steps of the process depending on the chosen method.\\

\begin{figure*}[!t]
\centering
	\begin{minipage}[t]{.48\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{../image/bloc_diagram_filtrage_EN.pdf} 
	\end{minipage}
	\begin{minipage}[t]{.48\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{../image/bloc_diagram_NMF_EN.pdf} 
	\end{minipage}
	\caption{Block diagrams summed up the different step of the precess. On top, for the low-pass filter, on bottom, for NMF.}
	\label{fig:block_diagram_protocol}
\end{figure*}

3 calculation steps are set up : 
\begin{itemize}
\item the dictionary building for NMF
\item the estimation of the traffic sound level according the chosen method (NMF or low-pass filter)
\item calculation of the error between the exact and the estimated sound levels.\\
\end{itemize}

\subsubsection{Dictionary building}

The dictionary is built from a sound database dedicated specially to this task. It is composed of 53 audio files of car passages. Multiple version of dictionaries are tested. First, for each audio file, its spectrogram is calculated with fixed parameters ($w = 2^{14}$, $noverlap = 75 \%$, $nfft = 2^{14}$). Then a temporal rectangular window of 0.5 second is applied without overlapping on the spectrogram. In each window, the root mean square value are calculated. This window allow to get multiples spectrum from an audio file.  An example, to illustrate the process, can be found on figure with a large window of 4 seconds. 

\begin{figure}[!t]
\centering
	\begin{minipage}[t]{.24\textwidth}
		\centering
		\includegraphics[width=\linewidth]{../image/extractionDictionary1Example.pdf} 
	\end{minipage}
	\begin{minipage}[t]{.24\textwidth}
		\centering
		\includegraphics[width=\linewidth]{../image/extractionDictionary2Example.pdf} 
	\end{minipage}
	\caption{Example of the extraction of the spectrum with a 4 seconds window. On left, the original spectrogram with the temporal window, on the left, the 4 spectrum obtained (dB scale)}
	\label{fig:dictionaryExtraction}
\end{figure}

As the number of spectrum got on all the sound database does not respect the constraint imposed about the dimension of NMF, a $K$-medoid clustering is applied to reduce the number of spectrum to $K = \left[ 25, 50, 100 \right]$. A special case is added where the root mean square of the entire spectrum is applied on all the spectrogram of the audio file. In consequence, one spectra is generated by audio file. 
% It consists in the estimation of the $K$-means and then to calculate the euclidean distance between each centroid with all the spectrum. The spectrum having the smaller distance with the centroid is then included in the dictionary $\mathbf{W}$.

\subsubsection{Estimation of the traffic sound level}
The traffic sound level is estimated according to the choice of the estimator (low-pass filter or NMF). These methods are applied on the totality of the corpus (\textit{alert} (al), \textit{animals} (an), \textit{humans} (hu), \textit{climate} (cl), \textit{mechanics} (me), \textit{transportation} (tr)), for all the cut-off frequencies $f_c$ ([500 1k 2k 5k 10k 20k] Hz) and for 5 $TPR$ ([-12 -6 0 6 12] dB).

\paragraph{Low-pass filter}\mbox{} \\
The first estimator to determine the traffic sound level is a basic low-pass filter which depend only on the cut-off frequencies $f_c$. As the road traffic is mainly composed of low frequencies (< 5000 Hz), this method considers that all the components located on the pass-band can be considered as road traffic. 

\paragraph{NMF}\mbox{} \\
The second estimator is NMF with the supervised and the semi-supervised approaches (see part \ref{part:nmf}). The spectrogram $\mathbf{V}$ and the dictionary $\mathbf{W}$ are expressed on two different formats: with a linear frequency scale ($\Delta f \approx 2.8$ Hz) and with third octave bands. Theses two methods enables to compare a fine approach (the linear scale) with a degraded one (the third octave bands) as it reduces the number of frequency bins (27 bands) and allows to reduces the number of bands in the high frequencies where the traffic component is less present. Furthermore, in the case of the linear frequency scale, $\mathbf{V}$ and $\mathbf{W}$ are filtered at the frequencies $f_c$ in order to focused the reconstruction of the signal of the low frequency bins. The $\beta$-divergence is reduced to the Kullback-Leibler divergence ($\beta = 1$) and to the Euclidean distance ($\beta = 2$). 400 iterations are performed. 
As only one sound source is considered in the dictionary, the source separation is performed following the equation  (\ref{eq:separationExtraction}). Also, if NMF is performed with filtered elements ($\mathbf{V}_{f_c}$ and $\mathbf{W}_{f_c}$) to determine $\mathbf{H}_{f_c}$, the traffic signal reconstruction is made with the original dictionary $\mathbf{W}$, as 

\begin{equation}
\mathbf{\tilde{V}}_{traffic} = \left[\mathbf{WH}_{f_c}\right]_{traffic}
\end{equation}

Then for each spectrogram, the estimated equivalent traffic sound level in dB of the entire scene, $\tilde{L}_{p,traffic}$, is calculated as well as the 1 second equivalent sound pressure level, $\tilde{p}_{1s,traffic}$. 

\subsubsection{Metric}
The performances of the two estimators to estimate the sound level of the traffic correctly are estimated through the calculation of two metrics based on the Root Mean Square Error (RMSE) : 

\begin{itemize}

\item the Mean Absolute Error, $MAE$, which consists in calculate for each combination of factors the absolute difference between the exact and estimated global traffic sound level in dB of the $N$ scenes.

\begin{equation}
MAE = \frac{\sum_{n = 1}^N\vert L^n_{p,traffic}-\tilde{L}^n_{p,traffic} \vert}{N}
\end{equation}

This metric expresses the quality of the long-term reconstruction of the signal. 

\item the global RMSE, \textit{gRMSE}, which consists in calculate for each combination of factors the error between the exact and estimated global traffic sound level in dB of the $N$ scenes.

\begin{equation}
gRMSE = \sqrt{\frac{1}{N}\sum_{n = 1}^N \left(L^n_{p,traffic}-\tilde{L}^n_{p,traffic}\right)^2}
\end{equation}

This metric expresses the quality of the long-term reconstruction of the signal. 
\item The normalized short-term RMSE, $nRMSE$, consists in calculate, for each sound mixture, the error between the 1-s equivalent sound level exact and estimated of the traffic of each file normalized by the 1-s equivalent sound level of the global mixture in the linear scale, 

\begin{equation}
nRMSE = \sqrt{\frac{1}{T}\sum_{t = 1}^T \left(\frac{p^t_{1s,traffic}-\tilde{p}^t_{1s,traffic}}{p^t_{1s,global}}\right)^2}
\end{equation}

with $T$ is the number of temporal bin in the signal. The linear scale is here more relevant than the dB scale as it is more sensitive to the error on the high sound levels. Then for one combination of factors, the $N$ $nRMSE$ calculated are averaged.\\
\end{itemize}

In all, 5940 settings are performed.

\section{Results}\label{part:results}

\subsection{Low-pass filter results}
In a first time, the low-pass filter estimator is performed on all the scene. The table \ref{tab:results_filter} sums up the mean error on the totality of the 750 scenes to find the cut-off frequency the most efficient on all the cases. \\

\begin{table}[h]
\centering
\begin{tabular}{llll}
$f_c$ (Hz) & $MAE$ (dB) & $nRMSE$ & $gRMSE$ (dB) \\ \hline
 500 & \textbf{\textcolor{red}{5.66 $\pm$6.59}} & \textbf{\textcolor{red}{1.48 $\pm$1.10}} & \textbf{\textcolor{red}{5.96 $\pm$6.70}} \\ 
 1000 & \textbf{6.31 $\pm$7.64} & \textbf{1.52 $\pm$1.34} & \textbf{6.52 $\pm$7.73} \\ 
 2000 & \textbf{6.65 $\pm$8.24} & \textbf{1.57 $\pm$1.54} & \textbf{6.80 $\pm$8.32} \\ 
 5000 & \textbf{7.42 $\pm$8.90} & 1.82 $\pm$1.65 & \textbf{7.44 $\pm$8.89} \\ 
10000 & \textbf{7.55 $\pm$9.00} & 1.89 $\pm$1.70 & \textbf{7.56 $\pm$8.99} \\ 
20000 & \textbf{7.59 $\pm$9.02} & 1.89 $\pm$1.72 & \textbf{7.59 $\pm$9.02} \\ 
\end{tabular} 
\caption{RMSE error for the low pass filter averaged on all the TPR and sub-classes}
\label{tab:results_filter}
\end{table}

According the table, the cut-off frequency at 500 Hz is the most efficient on all the TPR and all the sub-classes. The error for a 500 Hz cut-off frequency according to the sub-classes and the TPR is sums up in the figure \ref{fig:filterAmbiance}.\\

\begin{figure}[hbtp]
\centering
\includegraphics[width=\linewidth]{../image/filterAmbianceBar.pdf}
\caption{Bar plot for the low-pass filter according to the sub-classes and the TPR at 500 Hz cut-off frequency}
\label{fig:filterAmbiance}
\end{figure}

The error for all the sub-corpus is important for the low TPR (-12 and -6) due to the confusion of the \textit{perturbator} class as the traffic component whereas  it is not. The error is less for the \textit{alert} and \textit{humans} sub-corpus as it is composed of higher frequencies while for the \textit{climate} and \textit{transportation} the error is far more important. For the other TPR, the traffic is more present and become dominating on the \textit{perturbator} class. Then the error is due to the suppression of the traffic energy by the low-pass filter. 

\subsection{Supervised NMF results}

As it is not possible to summarize all the parameter combinations, just the best results according to the domain and $\beta$ are presented in table \ref{tab:results_supervised}. The bar plot in figure \ref{fig:nmfSupervisedAmbiance} display the $gRMSE$ error for the best combination.

\begin{table*}[h]
\centering
\begin{tabular}{lllllccc} 
$K$ & \shortstack{temporal\\window (ms)} & $f_c$ (Hz) & domain & $\beta$ & $MAE$ (dB) & $nRMSE$ & $gRMSE$ (dB)\\ 
\hline 
 25 & 500 & spectra &  2000 & 1 & \textbf{6.18 $\pm$7.49} & \textbf{1.48 $\pm$1.20} & \textbf{6.36 $\pm$7.55} \\ 
 25 & 500 & spectra &   500 & 2 & \textbf{\textcolor{red}{5.32 $\pm$6.28}} & \textbf{1.40 $\pm$0.93} & \textbf{\textcolor{red}{5.66 $\pm$6.38}} \\ 
 25 & 0 & thirdOctave & 20000 & 1 & \textbf{6.82 $\pm$8.16} & 1.60 $\pm$1.34 & \textbf{6.88 $\pm$8.15} \\ 
 25 & 500 & thirdOctave & 20000 & 2 & \textbf{6.26 $\pm$7.69} & \textbf{\textcolor{red}{1.36 $\pm$1.19}} & \textbf{6.36 $\pm$7.73} \\ 
\end{tabular} 
\caption{RMSE error for supervised NMF averaged on all the TPR and sub-classes}
\label{tab:results_supervised}
\end{table*}

\begin{figure}[hbtp]
\centering
\includegraphics[width=\linewidth]{../image/nmfAmbianceBar.pdf}
\caption{bar plot for the best parameter combination of the supervised NMF ($K = 25$, temporal window = 0.5 s, domain = spectra, $\beta$ = 2, $f_c$ = )}
\label{fig:nmfSupervisedAmbiance}
\end{figure}

The best combination for the supervised NMF is the one with described in the \textit{spectra} domain and for the euclidean distance with $K = 25$, the temporal window of 500 ms and $f_c = 500$ Hz. The errors produced by NMF is smaller than the filter approach for all the metrics. The figure \ref{fig:nmfSupervisedAmbiance} allows to see that the supervised NMF improves the estimation of the road traffic for $TPR = \left[-12~6\right]$ whereas the error for the higher $TPR$ is superior.\\

The evolution of the error for 3 sub classes (\textit{alert}, \textit{climate} and \textit{transportation}) and 2 \textit{TPR} (-6 and 6) are displayed in figures \ref{} and \ref{}.\\

\begin{figure}[!t]
\centering
	\begin{minipage}[t]{.24\textwidth}
		\centering
		\includegraphics[width=\linewidth]{../image/AmbianceNmfSupervised_EarlyStop_TPR6.pdf} 
	\end{minipage}
	\begin{minipage}[t]{.24\textwidth}
		\centering
		\includegraphics[width=\linewidth]{../image/AmbianceNmfSupervised_EarlyStop_TPR-6.pdf} 
	\end{minipage}
	\caption{Evolution of the $gRMSE$ for 3 sub-classes for 2 \textit{TPR}}
	\label{fig:RMSEevolution}
\end{figure}

We observe that the error if growing for TPR = -6, with an minimum in . The phenomena of early stop is present with few iteration . 
In contrary, for \textit{TPR} = 6, the  error is decreasing constantly. 

\subsection{Semi-supervised NMF results}
The error produced for the semi-supervised approach is summarize in table \ref{tab:results_semi_supervised}.

\begin{table*}
\centering
\begin{tabular}{cclllccc} 
$K$ & \shortstack{temporal\\window (ms)} & $f_c$ (Hz) & domain & $\beta$ & $MAE$ (dB) & $nRMSE$ & $gRMSE$ (dB) \\ 
\hline 
 &  &  & spectra & 1 &  &  &  \\ 
100 & 0 & 20000 & spectra & 2 & \textbf{4.02 $\pm$3.48} & \textbf{\textcolor{red}{1.14 $\pm$0.54}} & \textbf{\textcolor{red}{4.41 $\pm$3.69}} \\ 
50 & 0 & 20000 & third octave & 1 & \textbf{\textcolor{red}{3.88 $\pm$2.33}} & 1.29 $\pm$0.69 & \textbf{4.43 $\pm$2.71} \\ 
25 & 0 & 20000 & third octave & 2 & \textbf{4.29 $\pm$3.58} & 1.21 $\pm$0.61 & \textbf{4.74 $\pm$3.84} \\ 
\end{tabular} 
\caption{RMSE error for semi-supervised NMF averaged on all the TPR and sub-classes}
\label{tab:results_semi_supervised}
\end{table*}

The best combination is for the third octave domain with $f_c$ = 20 kHz, $K$ = 50 and a temporal window null. The error,  compared to the supervised approach,  is lower. Furthermore, the standard deviation is lower too meaning that the semi-supervised approach offer a much more stable error than the previous method. The figure \ref{} summarize the error for the best scenario expanded for the sub-classes and the TPR. 

\begin{figure}[hbtp]
\centering
\includegraphics[width=\linewidth]{../image/nmfAmbianceBar.pdf}
\caption{bar plot for the best parameter combination of the supervised NMF ($K = 25$, temporal window = 0.5 s, domain = spectra, $\beta$ = 2, $f_c$ = 20 kHz)}
\label{fig:nmfSemiSupervisedAmbiance}
\end{figure}

The mobile part of the dictionary, $\mathbf{W_r}$, is displayed in two particular sub-classes (\textit{alert}, which include harmonic sound sources, and \textit{climate}, composed of low frequencies) for two \textit{TPR} (-6 and 6).

For \textit{TPR} = -6, for the \textit{alert} sub-class, $\mathbf{W_r}$ enables to include the harmonic component which are not present in $\mathbf{W_s}$, the improvement bring by the semi-supervised approach is then remarkable. Whereas, in \textit{climate} sub-class, the \textit{perturbator}sound classes are composed of low-frequencies that are present in $\mathbf{W_s}$. This class might then be describe with the help of $\mathbf{W_s}$. 

In the opposite, for the high \textit{TPR}, for the \textit{climate} sub-class, the harmonic content disappears in $\mathbf{W_r}$ and is replace by low frequencies content that might be traffic component. 
In this approach, as the objective function of to minimize the distance between the spectrogram $\mathbf{V}$ and $\mathbf{WH}$, the semi-supervised approach is free to include traffic component in $\mathbf{W_r}$ to do it. This freedom deteriorates the reconstruction of the traffic signal. In the supervised approach, as $\mathbf{W}$ is only limited to the traffic spectrum. In consequence, NMF is constrained to use them to approximate $\mathbf{V}$, which improve the estimation of the traffic sound level for the high TPR. 


PLOT COST
PLOT RMSE
PLOT Lp 1s pour 2 ambiance 2 TPR


\section{Conclusion}
\footnotesize
\bibliographystyle{unsrt}
\bibliography{bibliographie_applied}

\end{document}

%\section{State of the art in the detection and separation tasks for environmental sounds}\label{part:stateOfArt}
%
%Many references have focused on the classification of the sound environments \cite{allegro_automatic_2001}, on the recognition \cite{defreville_automatic_2006} or one the detection of the  environmental sound events \cite{heittola_sound_2011}. This category of sound is not specific to the urban environment but includes all sound sources that are not related to music or speech. The algorithms are first learned on a known database to evaluate the performance of the algorithm then is applied to a second database simulating its application in real cases. To achieve these tasks, many approaches have the same generic pattern: a first extraction phase followed by a classification phase. In the first phase, the parameters of the characteristic are applied to an audio file to describe it, from the simplest, such as the sound level, the spectrum Gravity Centrums, the harmonicity to the most complex (Mel-Frequency Cepstral Coefficient, Perceptual Linear Prediction). In the second step, the characteristics are classified according to their evolution making it possible to distinguish the different categories of sounds. Common classification techniques are Hidden Markov Models, Artificial Neural Network, Gaussian Mixture Models and Support Vector Machines. Cowling and Sitte \cite{cowling_comparison_2003} summarize multiples of these extraction features and classification techniques that are used in \cite{shen_environmental_2012}, \cite{beritelli_pattern_2008}, \cite{couvreur_automatic_2004}. Even if each of them tested their algorithm on their own isolated sound database, specific database have been proposed to test and compare the performances of the algorithms as the DCASE database \cite{giannoulis_database_2013} or the TUT database \cite{mesaros_tut_2016}. Currently, the interest is focused on the use of the Neural Network in the case of the detection of acoustics events \cite{genaro_neural_2010} \cite{parascandolo_recurrent_2016}. 