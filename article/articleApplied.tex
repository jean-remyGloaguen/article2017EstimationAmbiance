\documentclass[twocolumn,a4paper,10pt]{article}

\input{../packageEN}
\input{../packageStyle}

\newcommand{\ml}[1]{\textcolor{blue}{ Mathieu: #1}}

\title{Estimation of the road traffic sound levels based on the Semi-Supervised Non-Negative Matrix Factorization of Magnitude Spectrograms}

\author{
    Jean-Rémy GLOAGUEN\\
    Arnaud Can\\
    LAE\\
    Ifsttar\\
    jean-remy.gloaguen@ifsttar.fr
  \and
    Mathieu Lagrange\\
	Jean-François Petiot \\
    LS2N\\
    Central School of Nantes\\
}
\date{}
\begin{document}

\maketitle

\section*{Abstract}

\section{Introduction}
With the introduction of the European Directive 2002/EC/49, cities over 100 000 inhabitants have to produce road traffic noise maps. It allows \ml{who ?}  to estimate the number of city dwellers exposed to high noise levels and to draw up action plans to reduce it as too long exposures to these noises can generate health problems \cite{who_burden_2017}. These maps are the result of a simulation process based on the estimation of the traffic density on the main roads and the use of sound propagation techniques. They express $L_ {DEN}$ and $L_N$, which are \textit{Day-Evening-Night} and \textit{Night} equivalent A-weighted sound levels respectively. However, these maps introduce lot of uncertainty generated by the numerical tools \cite{van_leeuwen_noise_2015}, by the different calculation methodologies used \cite{leroy_uncertainty_2010}\cite{garg_critical_2014} or even by the calculation procedure of the number of inhabitants exposed to noise \cite{king_implementation_2011}. In addition, the usual road traffic noise maps are static, aggregating the exposure on the two indicators $L_{DEN}$ and $L_N$, thus ignoring the sound levels evolution throughout the day. Since the creation of road traffic noise maps entails long data collection and calculation times, the use of acoustic measurements could facilitate their updating or even the generation of dynamic maps \cite{wei_dynamic_2016}. These measurements can be performed at fixed stations spread all over the cities \cite{Mioduszewski} \cite{mietlicki2012innovative}, which would lead to the availability of the long-term evolution of the traffic noise levels. It can also be performed with  mobile stations \cite{can_exploring_2012} \cite{manvell2004sadmam} covering a larger area with fewer sensors but also sparse time perdiods. The clustering between mobile and fixed measurements has been studied in \cite{can_measurement_2014}. \ml{je ne vois pas l'intéret de cette dernière phrase}

Currently, sensor networks in cities are spread for multiple applications (air quality assessment, measurement of meteorological parameters, ...), including the assessment of urban noise levels. DYNAMAP project \cite{dynamap_2016} studied the establishment and feasibility of such installations. It focuses on sensor installations on specific roads at the city scale in Milan and Rome \cite{bellucci_life_2017}. In a similar way, but reduced to few neighborhoods, the CENSE project\footnote{\url{http://cense.ifsttar.fr/}} \cite{} aims to combine \textit{in situ} observations, from a sensor network, and numerical data, from noise modeling, through data assimilation techniques.

If sensors networks could improve road traffic noise estimation compared with simulated maps, the issue of the correct estimation from  measurements of the traffic sound level is still unsolved \cite{Mioduszewski}. Indeed, the urban sound environment is a complex environment gathering lots of different sounds (car passages, voices, bird's whistles, car horn \dots) that can overlap. In consequence, the traffic sound level estimation based on measurements is not trivial task. \ml{parler ici de l'approche des espagnols. ref par email}

Many recent works have focused on the detection  or recognition tasks of environmental sounds \cite{heittola_sound_2011},  \cite{defreville_automatic_2006},  \cite{dufaux_automatic_2000}, \cite{chu_environmental_2009}. A two step process is generally followed : describe the audio files with a set of features (Spectrum Gravity Spectrum, harmonicity, Mel-Frequency Cepstral Coefficient \dots) and classify them with the help of classifiers (Support Vector Machines, Gaussian Mixture Models, Hidden Markov Model, Artifical Neural Networks). A description of there features and classifiers can be found in \cite{cowling_comparison_2003} and their application can be found in \cite{shen_environmental_2012}, \cite{beritelli_pattern_2008}, \cite{couvreur_automatic_2004}.
However, most of these results in the detection or recognition tasks, do not address the overlap of environmental sounds in an urban context. Although near major roads or ring roads traffic is predominant on all other sound sources, there are many places where road traffic overlaps with other sound sources that contribute significantly to the overall sound levels. In such case, the only detection of the traffic component does not make it possible to determine precisely its noise level. In consequence, to be effective on a wide range of sound environments, we propose in this paper to follow the blind source separation paradigm. That is, separating the contribution of the traffic from the other sources within a polyphonic scene.

One of the first and the most widely used techniques to do so is the Independent Component Analysis \cite{comon_independent_1994}. The principle is to decompose $N$ recorded signals to a sum of $P$ independent sound sources weighted by linear relations. This method is most of all suited for the 'cocktail party' issue where one tries to capture a signal among noise.  However, ICA is limited to only over determined cases ($N > P$). Furthermore, if it is suited for indoor environments where the number of sound sources is constant, it can not be fitted for an outdoor environment where the number of sources is unknown and variable and, moreover, it would be necessary to mount multiples sensors on one point to perform the source separation. A more convenient method is Non-negative Matrix Factorization (NMF) \cite{lee_learning_1999} which consists in approximating the magnitude spectrogram of an audio file from the product of two matrices. It has been widely used in the audio domain, \cite{smaragdis_non-negative_2003} \cite{wilson_speech_2008} \cite{mesaros_sound_2015}, and has already been employed for the source separation task of monaural signals of speech and music \cite{wang_musical_2005} \cite{wilson_speech_2008}. By design, this method deals with the overlaping sound sources as soon as the overlap can be resolved on the time/frequency plane. For the environmental sounds, the method has been used for the geo-localisation and classification of the sound environment, like in \cite{kumar_audio_2016} where NMF is used to classify the audio files according to the 10 cities where they have been recorded. It has also been used by Innami and Kasai in the unsupervised case \cite{satoshi_innami_nmf-based_2012} for source separation. They proposed a source separation in two steps by separating the sound background from the events first and by separating the events between them. The audio files tested results of a simulation process where a sound background (river or wind) are adding to two sound events (school chime, announcement, frog croaking, dog barging and bell ringing). If the method proposed is interesting, the main issue here is the small size of the database (only 9 sounds) on which the algorithms are tested while some sounds (frog and river) are not representative of sounds that can be found in cities.

We propose in this paper a method based on the Non-Negative Matrix Factorization technique to estimate the traffic sound level. To validate the approach, we consider a corpus of simulated (artifically created) scenes. The use of simulated sound scenes is necessary as it offers a full control on the design of the scenes and the knowledge of the exact contribution of the traffic component which would hardly be extracted from a recording of a urban scene.

The remaining of the paper is organized as follows. Section \ref{part:nmf} details the technical aspect of NMF. Section \ref{part:protocol} described on the experimental protocol setup. Then Section \ref{part:results} shows and discusses the results obtained during the parametric study.

\ml{faire une figure avec un diagrame de bloc et une section proposed approach avec des sub temps/frequence nmfsup nmfsemi}

\section{Non-negative Matrix Factorization}\label{part:nmf}
\subsection{Description of NMF}
Non-negative Matrix Factorization (NMF) is a matrix approximation method introduced by Lee and Seung, \cite{lee_learning_1999}, which can be used to approximate the spectrogram (obtained using a Short-Term Fourier Transform) of an audio file, $\mathbf{V}$, $\in \mathbb{R}^+_{F \times N}$ as :

\begin{equation}\label{eq:nmf}
\mathbf{V} = \mathbf{\tilde{V}} \approx \mathbf{WH}
\end{equation}

where $\mathbf{W} \in \mathbb{R}^+_{F \times K}$ is the \textit{dictionary} (or basis) matrix composed of audio spectrum and $\mathbf{H} \in \mathbb{R}^+_{K \times N}$ is the \textit{activation} matrix which summarizes the temporal evolution of each element of $\mathbf{W}$ (fig.  \ref{fig:example_NMF}).

\begin{figure}[hbtp]
\centering
\includegraphics[width=0.9\linewidth]{../image/illustration_NMF.PNG}
\caption{Example of a simple NMF  for a musical content \cite{bertin_les_2009}}
\label{fig:example_NMF}
\end{figure}

The choice of the dimensions should be such that $F\times K + K \times N < F \times N$. To estimate the quality of the approximation, an objective function is used

\begin{equation}\label{eq:min-D-WH}
\underset{\mathbf{H} \geq 0, \mathbf{W} \geq 0}{\min} D\left(\mathbf{V} \vert \vert \mathbf{\tilde{V}}\right)
\end{equation}

The operator $D(x\vert y)$ is a divergence calculation such as:
\begin{equation}
D\left(\textbf{V} \vert\vert \mathbf{\tilde{V}} \right) = \sum_{f = 1}^{F} \sum_{n = 1}^{N} d_{\beta}
\left(\textbf{V}_{fn} \vert \left[ \textbf{WH} \right]_{fn} \right)
\end{equation}

and usually belongs to the $\beta-$divergence class \cite{fevotte_nonnegative_2009} in which the well known Euclidean distance (eq. \ref{eq:def_distEUC}) and the Kullback-Leibler divergence (eq. \ref{eq:def_divKL}) belong

\begin{subequations}\label{eq:divBetaGenerale}
\begin{numcases}{d_{\beta}(x\vert y) =}
    \frac{1}{2}(x-y)^2, & $\beta = 2$, \label{eq:def_distEUC}\\
    x\log \dfrac{x}{y} - x + y, & $\beta = 1$.\label{eq:def_divKL}
\end{numcases}
\end{subequations}

Prior knowledge on the content can be adjusted with the addition of constraints (like the smoothness or the sparsness criteria \cite{virtanen_monaural_2007}) in the objective function (equation (\ref{eq:min-D-WH})) to better take account prior knowledge of the sources.

Algorithms have been proposed to solve the minimization problem (\ref{eq:min-D-WH}) iteratively such as the multiplicative update, the alternating least square method \cite{cichocki_regularized_2007}, the projected gradient \cite{lin_projected_2007} \dots Here, the multiplicative update is chosen \cite{lee_algorithms_2000} as it ensure non-negative results of which convergence has been proved \cite{fevotte_algorithms_2011}.

\subsection{Supervised NMF}
First, supervised NMF is used: the \textit{dictionary} includes audio spectrum of urban sound sources as, in the urban environments, a lot of different sound sources present are known and their spectrum can be obtained. The \textit{basis} are then the unknown to estimate. In the first iteration, $\mathbf{H}$ is initialized randomly, then it is updated by the generic algorithm

\begin{equation}
\textbf{H}^{(i+1)} \leftarrow \textbf{H}^{(i)}.\left(\frac{\textbf{W}^T \left[\left(\textbf{WH}^{(i)} \right)^{(\beta-2)}.\textbf{V} \right]}{\textbf{W}^T \left[\textbf{WH}^{(i)} \right]^{(\beta-1)}}\right)^{\gamma(\beta)}
\end{equation}

with $\gamma(\beta) = \frac{1}{2-\beta},$ for $\beta < 1$, $ \gamma(\beta) = 1$, for $\beta \in \left[1,2\right]$ and $\gamma(\beta) = \frac{1}{\beta-1}$ for $\beta > 2$. The product $A.B$ and $A/B$ symbolized the Hadamard product and ratio. The source separation is made by extracting the dictionary and basis elements related to the traffic

\begin{equation}\label{eq:separationExtraction}
\mathbf{\tilde{V}}_{traffic} = \left[ \mathbf{WH} \right]_{traffic}
\end{equation}

%or by generating a soft mask, $\mathbf{M_s}$,
%
%\begin{equation} \label{eq:definitionMask}
%\mathbf{M_s} = \frac{\left[\mathbf{W} \mathbf{H}\right]_{traffic}}{\mathbf{W H}},
%\end{equation}
%
%which allows to determine the spectrogram of the traffic component, $ \mathbf{\tilde{V}}_{traffic}$
%
%\begin{equation}\label{eq:separation}
%\mathbf{\tilde{V}}_{traffic} = \mathbf{M_s}.\mathbf{V}.
%\end{equation}

\subsection{Semi-supervised NMF}

One of the main issue with the supervised approach is To better acount for the diverse nature of urban scenes, semi-supervised NMF can be useful as it has been proposed \cite{lee_semi-supervised_2010}  to offer more flexibility. This method consists in composing the \textit{dictionary} with a fixed part $\mathbf{W_s} \in \mathbb{R}^+_{F\times K}$, composed in our case of spectrum representative of road traffic and with a mobile part, $\mathbf{W_r} \in \mathbb{R}^+_{F\times J}$ with $J <<K$, that is updated. Here, $J = 2$. The aim is to include in $\mathbf{W_r}$ the element that are not related with the traffic. The problem (\ref{eq:nmf}) become

\begin{equation}
\mathbf{V} \approx \mathbf{W_s H_s}+ \mathbf{W_r H_r}
\end{equation}

In a similar way as to solve the equation \ref{eq:min-D-WH}, $\mathbf{W_r}$, $\mathbf{H_r}$ and $\mathbf{H_s}$ are successively updated with the relations (\ref{eq:WH-SSupdate}):

{\scriptsize
\begin{subequations}\label{eq:WH-SSupdate}
\begin{align}
\mathbf{W_r}^{(i+1)} &\leftarrow \mathbf{W_r}^{(i)}.\left(\frac{\left[\left(\mathbf{W_r H_r}^{(i)} \right)^{(\beta-2)}.\mathbf{V} \right]\mathbf{H_r}^T}{\left(\mathbf{W_r H_r}^{(i)} \right)^{(\beta-1)}\mathbf{H_r}^T}\right)^{\gamma(\beta)}\label{eq:W_r_SS}\\
\mathbf{H_r}^{(i+1)} &\leftarrow \mathbf{H_r}^{(i)}.\left(\frac{\mathbf{W_r}^T \left[\left(\mathbf{W_r H_r}^{(i)} \right)^{(\beta-2)}.\mathbf{V} \right]}{\mathbf{W_r}^T \left(\mathbf{W_r H_r}^{(i)} \right)^{(\beta-1)}}\right)^{\gamma(\beta)}\label{eq:H_r_SS}\\
\mathbf{H_s}^{(i+1)} &\leftarrow \mathbf{H_s}^{(i)}.\left(\frac{\mathbf{W_s}^T \left[\left(\mathbf{W_s H_s}^{(i)} \right)^{(\beta-2)}.\mathbf{V} \right]}{\mathbf{W_s}^T \left(\mathbf{W_s H_s}^{(i)} \right)^{(\beta-1)}}\right)^{\gamma(\beta)}\label{eq:H_s_SS}
\end{align}
\end{subequations}}

%This approach has been used TO COMPLETE.

\section{Experimental protocol}\label{part:protocol}

In order to vzlidate the usefulness of considering the NMF framewrok to estimate the road traffic noise level, one need to have a reference level. It can hardly de measured or even annotated from real life recordings. Thus,  simulated sound scenes are used to assess the performance of the propsed NMF. This offers a controlled framework to design specific sound environments in which all the traffic component is known. Then, the road traffic sound levels estimated with the method can be compared to the real ones, introduced within each simulated sound scene.

\subsection{Environmental sound scene corpus}

A corpus is designed with the \textit{simScene} software\footnote{Open-source project available at: \url{https://bitbucket.org/mlagrange/simscene}}. \textit{simScene} \cite{rossignol_simscene:_2015} is a simulator that creates sound scenes in a .wav format by summing audio samples that come from an isolated sound database. This database is divided in two categories: $i)$ the \textit{event} category which are the brief sounds (from 1 to 20 seconds) that are considered as salient, $ii)$ the \textit{background} category includes all the sounds that are of long duration and whose acoustic properties do not vary with respect to time. Inside each category, the sound samples are grouped in sound classes (\textit{bird, car, foot steps} \dots), each of them being composed of multiples samples (bird01.wav, bird02.wav \dots).

The software allows the user to control some parameters (number of events of each class that appear in the mixture, elapsed time between each sample of a same class, presence of a fade in and a fade out \dots) completed with a standard deviation that may brings some random behavior between the scenes. Furthermore, an audio file of each sound class present in the scene can be generated that allows to know its exact contribution as well as a text file that summarizes the time presence of all the events.\\

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{../image/exampleSimScene2.pdf}
\label{fig:exampleSimScene}
\caption{Example of a sound scene composed of 3 sound classes (car, bird, car horn)}
\end{figure}

A sound database has been built including 245 sound event samples divided in 19 sound classes (\textit{ringing bell, birds, sweeping broom, car horn, car passages, hammer, drill, coughing, barking dog, rolling suitcase, closing door, plane, siren, footstep, storm, street noise, train, tramway, truck and voice}) and 154 sound background samples divided in 9 sound classes (\textit{birds, construction site noise, crowd, park, rain, children playing in schoolyard, constant traffic noise, ventilation, wind}). The sound class \textit{car passages} comes from recordings of 4 cars made on the Ifsttar's runway on different speeds with multiple gear ratio. The other audio files have been found online (\textit{freesound.org}) and within the \textit{UrbanSound8k} database \cite{salamon_dataset_nodate}. This database enables creating realistic urban sound scenes from the road traffic point of view \cite{gloaguen_creation_2017}. A sound mixing corpus is composed of 6 sub-corpuses of 25 audio files each lasting 30 seconds. Each sub-corpus is characterized by a specific generic sound class that summed with traffic will make the estimation of the traffic level more difficult. The classes are : \textit{alert} (car horn, siren), \textit{animals} (barking dog , whistling birds), \textit{climate} (wind, rain), \textit{humans} (crowd noise and voice), \textit{mechanics} (different metallic and construction site noise) and \textit{transportation} (train, tramway and plane). In each file, traffic component is present as the sum of the background and event traffic sounds and is mixed with the sound classes. The sound classes that are not related to the traffic component are summed up as the \textit{interfering} sound class. To test different scenarios, each audio file is duplicated with the traffic sound level of the entire sound scene, $L_{p,traffic}$, fixed to a specific level according to the sound level of the \textit{interfering} class, $L_{p,interfering}$ following the relation (\ref{eq:tpr}).

\begin{equation}\label{eq:tpr}
TPR = L_{p,traffic}-L_{p,interfering}
\end{equation}

with the \textit{Traffic Interference Ratio} $TIR = \left[-12, -6, 0, 6, 12\right]$. When $TIR = -12$, the traffic component is then less present than when $TIR = 12$ where it is predominant on the \textit{perturbator} class. The 1 second equivalent sound pressure level, $p_{1s,traffic}$, is also calculated (figure \ref{fig:exampleScene}). Finally, the number of scenes designed is 750 (6 sub-corpus $\times$ 25 scenes $\times$  5 TPR values).

\begin{figure*}
\centering
   \begin{minipage}[c]{.32\linewidth}
      \includegraphics[width =\linewidth]{../image/spectrogramExample.pdf}
   \end{minipage}
   \begin{minipage}[c]{.32\linewidth}
      \includegraphics[width =\linewidth]{../image/animals_10-pianoRoll.png}
   \end{minipage}
   \begin{minipage}[c]{.32\linewidth}
      \includegraphics[width =\linewidth]{../image/evolutionLpExample.pdf}

   \end{minipage}
\caption{Example of a scene of the \textit{animals} sub corpus. Spectrogram (on left), \textit{Piano Roll} of the different sound classes (on the middle) and 1-s equivalent sound level of the traffic, $Lp_{1s,traffic}$ and of the global sound scene, $Lp_{1s,global}$(on right)}
\label{fig:exampleScene}
\end{figure*}

\subsection{Experiment}

The experiment consists in estimating the traffic road sound level on the environmental sound corpus. NMF is used and compared to a simple approach which consist in a frequency low-pass filter (this second method relies on the fact that road traffic is mainly composed of low frequencies, compared to main of the confounded sounds (voices, birds, etc.)) with the cut-off frequency $f_c$. The spectrogram $\mathbf{V}$ is built with a window size $w = 2^{14}$ with a 75 $\%$ overlapping and a number of point $nfft = 2^{14}$. Therefore, the dimensions of $V$ are $F$ = 8192 and $N$ = 772.  Similarly, the frequency low-pass filter is applied on the spectrogram $\mathbf{V}$ and on the dictionary $\mathbf{W}$ ( renamed $\mathbf{V}_{f_c}$ and $\mathbf{W}_{f_c}$ respectively). The aim to focus the reconstruction of the signal on the frequencies where the traffic components are. The figure \ref{fig:block_diagram_protocol} summarizes the different steps of the process depending on the chosen method, which consist of 3 steps:

\begin{itemize}
\item the dictionary building for NMF,
\item the estimation of the traffic sound level according the chosen method (NMF or frequency low-pass filter),
\item the calculation of the error between the exact and the estimated sound levels.\\
\end{itemize}

\begin{figure*}[!t]
\centering
	\begin{minipage}[t]{.48\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{../image/bloc_diagram_filtrage_EN.pdf}
	\end{minipage}
	\begin{minipage}[t]{.48\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{../image/bloc_diagram_NMF_EN.pdf}
	\end{minipage}
	\caption{Block diagrams summed up the different step of the precess. On top, for the frequency low-pass filter, on bottom, for NMF.}
	\label{fig:block_diagram_protocol}
\end{figure*}

\subsubsection{Dictionary building}

The dictionary is built from a sound database dedicated specially to this task. It is composed of 53 audio files of car passages. First, for each audio file, its spectrogram is calculated with fixed parameters ($w$, 75 $\%$ overlap, $nfft$). Then a temporal rectangular window is applied without overlapping on the spectrogram in order to consider several spectrum for each audio file. The size of the window is set up at 0.5 and 1 second. In each window, the root mean square value is calculated on each frequency bin to reduce the different spectrum in one spectra.  An example that illustrates the process can be found on figure \ref{fig:dictionaryExtraction} in the ease of a large window of 4 seconds.

\begin{figure}[!t]
\centering
	\begin{minipage}[t]{.24\textwidth}
		\centering
		\includegraphics[width=\linewidth]{../image/extractionDictionary1Example.pdf}
	\end{minipage}
	\begin{minipage}[t]{.24\textwidth}
		\centering
		\includegraphics[width=\linewidth]{../image/extractionDictionary2Example.pdf}
	\end{minipage}
	\caption{Example of the extraction of the spectrum with a 1 second window. On left, the original spectrogram with the temporal window, on the left, the 4 spectrum obtained (dB scale)}
	\label{fig:dictionaryExtraction}
\end{figure}

However, the number of elements got on all the sound database does not respect the constraint imposed about the dimension of NMF ($F \times K + K \times N < F \times N$). With a 1 second window, $K$ = 1003. In consequence, a $K$-medoid clustering is applied to reduce the number of spectrum to $K = \left[ 25, 50, 100 \right]$. A special case is added where the root mean square of \textit{all} the spectrogram is applied. One spectra is then generated by audio file.
Each element is normalized such as $\vert \vert \mathbf{W_k} \vert \vert = 1$ with $\vert \vert \bullet \vert\vert$ is the $\ell-1$ norm. Table \ref{tab:dictionary_factors} summarizes the parameters and their related values.

\begin{table}[h]
\centering
\begin{tabular}{cccc}
$K$ & 25  & 50 & 100 \\ \hline
\begin{tabular}[c]{@{}c@{}}\textbf{temporal} \\ \textbf{window (s)}\end{tabular} & 0.5 & 1  & \textit{all}
\end{tabular}
\caption{Summary of the dictionary parameters}
\label{tab:dictionary_factors}
\end{table}

\subsubsection{Estimation of the traffic sound level}
The traffic sound level is estimated according to the choice of the estimator (a frequency low-pass filter or NMF). These methods are applied on the totality of the corpus (\textit{alert} (al), \textit{animals} (an), \textit{humans} (hu), \textit{climate} (cl), \textit{mechanics} (me), \textit{transportation} (tr)), for all the cut-off frequencies $f_c$ ([500 1k 2k 5k 10k 20k] Hz) and for 5 $TPR$ ([-12 -6 0 6 12] dB).

\paragraph{Frequency low-pass filter}\mbox{} \\
The first estimator to determine the traffic sound level is a basic frequency low-pass filter which depend only on the cut-off frequencies $f_c$.

\paragraph{NMF}\mbox{} \\
The second estimator is supervised and semi-supervised NMF (see part \ref{part:nmf}). The spectrogram $\mathbf{V}$ and the dictionary $\mathbf{W}$ are expressed on two different formats: with a linear frequency scale ($\Delta f \approx 2.8$ Hz) and with third octave bands (27 bands). Theses two methods enable to compare a fine approach (the linear scale) with a degraded one (the third octave bands) as it reduces the number of frequency bins and allows to reduces the number of bands in the high frequencies where the traffic component is less present. NMF is performed on 400 iterations which is sufficiently enough to get a stabilized reconstruction. Furthermore, in the case of the linear frequency scale, $\mathbf{V}$ and $\mathbf{W}$ are filtered at the frequencies $f_c$ in order to focused the reconstruction of the signal of the low frequency bins. In consequence, if NMF is performed with filtered elements ($\mathbf{V}_{f_c}$ and $\mathbf{W}_{f_c}$) to determine $\mathbf{H}_{f_c}$, the traffic signal reconstruction is made with the original dictionary $\mathbf{W}$, as

\begin{equation}
\mathbf{\tilde{V}}_{traffic} = \left[\mathbf{WH}_{f_c}\right]_{traffic}
\end{equation}

For the third octave frequency scale, only the case $f_c = 20$ kHz is applied.
During the iteration process, the estimated equivalent traffic sound level in dB of the entire scene, $\tilde{L}_{p,traffic}$, is calculated as well as the 1 second equivalent sound pressure level, $\tilde{p}_{1s,traffic}$. Table \ref{tab:estimation_factors} summarizes the parameters and their related values.

\begin{table*}[]
\centering
\begin{tabular}{lcccccc}
$\mathbf{f_c}$ (kHz) & 0.5 & 1 & 2 & 5 & 10 & 20 \\ \hline
$\mathbf{TPR}$ (dB) & -12 & -6 & 0 & 6 & 12 &  \\ \hline
\textbf{sub-classes} & alert & animals & climate & humans & transportation & mechanics \\ \hline
\textbf{method} & \multicolumn{2}{c}{filter} & \multicolumn{2}{c}{supervised NMF} & \multicolumn{2}{c}{semi-supervised NMF} \\ \hline
$\mathbf{\beta}$ & \multicolumn{3}{c}{1} & \multicolumn{3}{c}{2} \\ \hline
\begin{tabular}[c]{@{}c@{}}\textbf{frequency} \\ \textbf{scale}\end{tabular} & \multicolumn{3}{c}{linear} & \multicolumn{3}{c}{third octave}
\end{tabular}
\caption{Summary of the different parameters and their values for the estimation of the traffic sound level}
\label{tab:estimation_factors}
\end{table*}

\subsubsection{Metric}
The performances of the two estimators of the road traffic sound level are assessed through the calculation of two metrics.

\begin{itemize}

\item The Mean Absolute Error, $MAE$, expresses the quality of the long-term reconstruction of the signal. It consists in the average over the $N$ sound scenes of the absolute difference between the exact and estimated traffic sound level in dB,

\begin{equation}
MAE = \frac{\sum_{n = 1}^N\vert L^n_{p,traffic}-\tilde{L}^n_{p,traffic} \vert}{N}.
\end{equation}

\item The normalized short-term Root Mean Square Error, $nRMSE$, calculates, for each sound scene, the error between the exact and estimated road traffic 1-s equivalent sound level of each file normalized by the 1-s equivalent sound level of the global scene, $p^t_{1s,global}$, in the linear scale,

\begin{equation}
nRMSE = \sqrt{\frac{1}{T}\sum_{t = 1}^T \left(\frac{p^t_{1s,traffic}-\tilde{p}^t_{1s,traffic}}{p^t_{1s,global}}\right)^2}
\end{equation}

with $T$ is the number of temporal bin in the signal. The linear scale is here more relevant as it is more sensitive to the error on the high sound levels than the dB scale. Then for one combination of factors, the $N$ $nRMSE$ calculated are averaged.\\
\end{itemize}

In all, according the table \ref{tab:dictionary_factors} and \ref{tab:estimation_factors}, 6848 settings are performed between the different dictionary $\mathbf{W}$ and the multiple parameters of the estimation step.

\section{Results}\label{part:results}

\subsection{Frequency low-pass filter results}
In a first time, the frequency low-pass filter estimator is performed on all the scene. The table \ref{tab:results_filter} summarized the mean error on the totality of the 750 scenes to find the most efficient cut-off frequency. \\

\begin{table}[h]
\centering
\begin{tabular}{llll}
$f_c$ (Hz) & $MAE$ (dB) & $nRMSE$  \\ \hline
 500 & \textbf{\textcolor{red}{5.66 $\pm$6.59}} & \textbf{\textcolor{red}{1.48 $\pm$1.10}} \\
 1000 & \textbf{6.31 $\pm$7.64} & \textbf{1.52 $\pm$1.34} \\
 2000 & \textbf{6.65 $\pm$8.24} & \textbf{1.57 $\pm$1.54} \\
 5000 & \textbf{7.42 $\pm$8.90} & 1.82 $\pm$1.65 \\
10000 & \textbf{7.55 $\pm$9.00} & 1.89 $\pm$1.70 \\
20000 & \textbf{7.59 $\pm$9.02} & 1.89 $\pm$1.72 \\
\end{tabular}
\caption{RMSE error for the low pass filter averaged on all the TPR and sub-classes}
\label{tab:results_filter}
\end{table}

According the table \ref{tab:results_filter}, the cut-off frequency at 500 Hz is the most efficient on all the TPR and all the sub-classes. The corresponding errors according to the sub-classes and the TPR are summarized in the figure \ref{fig:filterAmbiance}.\\

\begin{figure}[hbtp]
\centering
\includegraphics[width=\linewidth]{../image/AmbianceFilter.pdf}
\caption{Bar plot for the filter according to the sub-classes and the TPR at $f_c$ = 500 Hz cut-off frequency}
\label{fig:filterAmbiance}
\end{figure}

The error for all the sub-corpus is important for the low TPR (-12 and -6) due to the confusion between the \textit{perturbator} class and the \textit{traffic} class. The error is less for the \textit{alert} and \textit{humans} sub-corpus as it is composed of higher frequencies while, for other sub-classes, the error are far more important. For the higher \textit{TPR}, the traffic is more present and become dominating on the \textit{perturbator} class. The lower error, here, is due to the suppression of the traffic energy by the filter. Finally, the error for $f_c = 20$ kHz is equivalent to the one produced when the \textit{traffic} and the \textit{perturbator} classes are take into account together without distinction.

\subsection{Supervised NMF results}

As it is not possible to summarize all the parameter combinations, just the best results according to the domain and $\beta$ at the $\nth{400}$ iteration are presented in table \ref{tab:results_supervised}. The bar plot in figure \ref{fig:nmfSupervisedAmbiance} displays the $MAE$ error for the best combination.\\

\begin{table*}[t]
\centering
\begin{tabular}{lllllcc}
$K$ & \shortstack{temporal\\window (ms)} & $f_c$ (Hz) & domain & $\beta$ & $MAE$ (dB) & $nRMSE$ \\
\hline
 25 & 500 & spectra &  2000 & 1 & \textbf{6.18 $\pm$7.49} & \textbf{1.48 $\pm$1.20} \\
 25 & 500 & spectra &   500 & 2 & \textbf{\textcolor{red}{5.32 $\pm$6.28}} & \textbf{1.40 $\pm$0.93} \\
 25 & 0 & third octave & 20000 & 1 & \textbf{6.82 $\pm$8.16} & 1.60 $\pm$1.34\\
 25 & 500 & third octave & 20000 & 2 & \textbf{6.26 $\pm$7.69} & \textbf{\textcolor{red}{1.36 $\pm$1.19}} \\
\end{tabular}
\caption{RMSE error for supervised NMF averaged on all the TPR and sub-classes}
\label{tab:results_supervised}
\end{table*}

\begin{figure}[h]
\centering
\includegraphics[width=\linewidth]{../image/AmbianceNmfSupervised.pdf}
\caption{bar plot for the best parameter combination of the supervised NMF ($K = 25$, temporal window = 0.5 s, domain = spectra, $\beta$ = 2, $f_c$ = 500 Hz )}
\label{fig:nmfSupervisedAmbiance}
\end{figure}

\begin{table}[h]
\centering
\begin{tabular}{ccc}
    & \multicolumn{2}{c}{$MAE$ (dB)} \\ \hline
TPR & filtre & supervised NMF \\ \hline
 -12 & 17.20 $\pm$ 4.09 & 15.76 $\pm$ 5.82 \\
 -6 &  6.91 $\pm$ 2.82 & 6.32 $\pm$ 3.24\\
 0 & 1.09 $\pm$ 0.16 & 1.18 $\pm$ 0.19\\
  6 &  1.47 $\pm$ 0.12 & 1.59 $\pm$ 0.13\\
 12 &  1.60 $\pm$ 0.16 & 1.77 $\pm$ 0.07
\end{tabular}
\caption{Comparison of the $MAE$ error for the filter at 500 Hz and the best combinaison of the supervised NMF}
\label{tab:resultsComparison}
\end{table}


The best combination for supervised NMF is the one with described in the \textit{spectra} domain and for the euclidean distance with $K = 25$, a temporal window of 500 ms and $f_c = 500$ Hz. The errors produced by NMF, on the totality of the scenes, is smaller than the filter approach for all the metrics. For the higher \textit{TPR}, both methods have similar performances (table \ref{tab:resultsComparison}). For the lower \textit{TPR}, TPR, supervised NMF reduces significantly the error. By distinguishing each class, it is lower for the \textit{alert} and \textit{animals} than the rest sub-classes. \\

This difference can be illustrate through the evolution of the cost function (figures \ref{fig:costSup12}) and of the $MAE$ error (figure \ref{fig:EarlyStop12}) for 3 sub-classes (\textit{alert}, \textit{climate} and \textit{transportation}), for 2 \textit{TPR} (-6 and 6) until the $\nth {100}$ iterations.\\

\begin{figure}
    \centering
    \subfigure[]{\label{fig:EarlyStop1}
    \includegraphics[width=0.45\linewidth]{../image/AmbianceNmfSupervised_EarlyStop_TPR-6.pdf}}
    \subfigure[]{\label{fig:EarlyStop2} \includegraphics[width=0.45\linewidth]{../image/AmbianceNmfSupervised_EarlyStop_TPR6.pdf}}
    \caption{Evolution of the $MAE$ for 3 sub-classes for TPR = -6 (fig.  \ref{fig:EarlyStop1}) and TPR = 6 (fig. \ref{fig:EarlyStop2})}
    \label{fig:EarlyStop12}
\end{figure}

\begin{figure}
    \centering
    \subfigure[]{\label{fig:costSup1}
    \includegraphics[width=0.45\linewidth]{../image/AmbianceNmfSupervised_EarlyStop_TPR-6Cost.pdf}}
    \subfigure[]{\label{fig:costSup2} \includegraphics[width=0.45\linewidth]{../image/AmbianceNmfSupervised_EarlyStop_TPR6Cost.pdf}}
    \caption{Evolution of the $MAE$ for 3 sub-classes for TPR = -6 (fig.  \ref{fig:costSup1}) and TPR = 6 (fig. \ref{fig:costSup2})}
    \label{fig:costSup12}
\end{figure}

For the TPR = 6, the cost function and the $MAE$ error are decreasing, meaning the global mixture and the traffic signal are well synthesized. Here as the $\mathbf{W}$ is only composed of traffic elements and the sound scenes are composed of a predominant traffic, the reconstruction of the signal is easier. In opposite, for the case where \textit{TPR} = -6, for the \textit{alert} signal, the cost function and the $MAE$ error are decreasing too. But for the \textit{climate} and \textit{transportation} sub-classes, the $MAE$ error is increasing. Even if the cost function decreases, the quality of the traffic signal rebuilt is not improved. This difference can be explained by the type of sound present in these different sub-classes: for \textit{alert} and \textit{animals}, it includes harmonic sounds which belong in the frequency range $\left[2000-5000\right]$ Hz while the other sub-classes include lower frequency sounds.  As $\mathbf{W}$ is composed of traffic spectrum, located in low frequencies too, it is more difficult to recompose correctly the traffic signal when the \textit{perturbator} sound is predominant and composed of low frequencies too. As NMF minimized the cost function (equation \ref{eq:min-D-WH}), \textit{traffic} spectrum then are used to synthesized the global mixture at the expense of the traffic signal.

\subsection{Semi-supervised NMF results}

The errors produced for the semi-supervised approach is summarized in table \ref{tab:results_semi_supervised} according to $\beta$ and the frequency domain (spectral or third octave).\\

\begin{table*}
\centering
\begin{tabular}{cclllccc}
$K$ & \shortstack{temporal\\window (ms)} & $f_c$ (Hz) & domain & $\beta$ & $MAE$ (dB) & $nRMSE$ \\
\hline
 50 & 0 & spectra &  1000 & 1 & \textbf{4.50 $\pm$3.05} & 1.45 $\pm$0.76 \\
100 & 0 & spectra & 20000 & 2 & \textbf{4.05 $\pm$3.43} & \textbf{\textcolor{red}{1.16 $\pm$0.53}} \\
 25 & 0 & third octave & 20000 & 1 & \textbf{\textcolor{red}{3.96 $\pm$2.18}} & 1.34 $\pm$0.72 \\
 25 & 0 & third octave & 20000 & 2 & \textbf{4.29 $\pm$3.58} & \textbf{1.21 $\pm$0.61}
\end{tabular}
\caption{RMSE error for semi-supervised NMF averaged on all the TPR and sub-classes}
\label{tab:results_semi_supervised}
\end{table*}

The best combination is got in the third octave domain with $\beta = 1$, $f_c$ = 20 kHz, $K$ = 25 and a temporal window null. The error, compared to the supervised approach, is lower. Furthermore, the standard deviation is lower too meaning that the semi-supervised approach offer a much more stable error than the previous method. The figure \ref{fig:nmfSemiSupervisedAmbiance} displayed the error for the best scenario averaged on all the sub-classes and the \textit{TPR}. The table \ref{tab:comparisonFilterSemiSupervised} summarizes the error expanded to the \textit{TPR}.

\begin{figure}[hbtp]
\centering
\includegraphics[width=\linewidth]{../image/AmbianceNmfSemiSupervised.pdf}
\caption{bar plot for the best parameter combination of the supervised NMF ($K = 25$, temporal window = 0.5 s, domain = spectra, $\beta$ = 2, $f_c$ = 20 kHz)}
\label{fig:nmfSemiSupervisedAmbiance}
\end{figure}

\begin{table}
\centering
\begin{tabular}{cccc}
    & \multicolumn{2}{c}{$MAE$ (dB)} \\ \hline
TPR & filter & semi-Supervised NMF \\ \hline
 -12 & 17.20 $\pm$4.09 &  7.46 $\pm$2.88 \\
 -6 &  6.91 $\pm$2.82 & 2.15 $\pm$0.70\\
 0 & 1.09 $\pm$0.16 &  2.20 $\pm$0.45\\
 6 &  1.47 $\pm$0.12 &  3.61 $\pm$0.29\\
 12 &  1.60 $\pm$0.16 &  4.02 $\pm$0.33\\
\end{tabular}
\caption{Comparison of the baseline and semi-supervised NMF with the best combination}
\label{tab:comparisonFilterSemiSupervised}
\end{table}

The error for low TPR is much lower than the filter or supervised NMF. The add of the mobile part makes NMF less constraint and therefore allows to adapt NMF to low traffic contents. Figure display the mobile part of the dictionary, $\mathbf{W_r}$ for two particular sub-classes (\textit{alert} and \textit{climate} and for \textit{TPR} = -6.\\


\textbf{figure $W_r$ for alert and climate}\\

Nevertheless, the advantage won with the mobile part, generates larger errors in higher \textit{TPR}. Here, NMF uses $\mathbf{W_r}$ in order to minimize the cost function. As the mobile part is not constraint, traffic content is included in it, decreasing the quality of the traffic signal reconstruction. Figure display the 2 basis of $\mathbf{W_r}$. \\

\textbf{figure $W_r$ for alert and climate}\\

These behaviors can be noticed through the $MAE$ evolution in figures \ref{fig:EarlyStopSemi12}: for low TPR the error is decreasing like the cost function (figure \ref{fig:costSemiSup1}) meaning that the synthesis of the traffic signal is good. For the \textit{alert} sub-class, $\mathbf{W_r}$ enables to include the harmonic component which are not present in $\mathbf{W_s}$, the improvement bring by the semi-supervised approach is then remarkable. Whereas, in \textit{climate} sub-class, the \textit{perturbator} sound classes are composed of low-frequencies that are present in $\mathbf{W_s}$. This class might be describe with the help of $\mathbf{W_s}$.

For \textit{TPR} = 6, the error is increasing for all sub-classes. As the objective function is to minimize the distance between the spectrogram $\mathbf{V}$ and $\mathbf{WH}$, the semi-supervised approach is free to include traffic component in $\mathbf{W_r}$ to do it. This degree of freedom deteriorates the reconstruction of the traffic signal. \\

\begin{figure}
    \centering
    \subfigure[]{\label{fig:EarlyStopSemi1}
    \includegraphics[width=0.45\linewidth]{../image/AmbianceNmfSemiSupervised_EarlyStop_TPR-6.pdf}}
    \subfigure[]{\label{fig:EarlyStopSemi2} \includegraphics[width=0.45\linewidth]{../image/AmbianceNmfSemiSupervised_EarlyStop_TPR6.pdf}}
    \caption{Evolution of the $MAE$ for 3 sub-classes for TPR = -6 (fig.  \ref{fig:EarlyStopSemi1}) and TPR = 6 (fig. \ref{fig:EarlyStopSemi2})}
    \label{fig:EarlyStopSemi12}
\end{figure}

\begin{figure}
    \centering
    \subfigure[]{\label{fig:costSemiSup1}
    \includegraphics[width=0.45\linewidth]{../image/AmbianceNmfSemiSupervised_EarlyStop_TPR-6Cost.pdf}}
    \subfigure[]{\label{fig:costSemiSup2} \includegraphics[width=0.45\linewidth]{../image/AmbianceNmfSemiSupervised_EarlyStop_TPR6Cost.pdf}}
    \caption{Evolution of the $MAE$ for 3 sub-classes for TPR = -6 (fig.  \ref{fig:costSemiSup1}) and TPR = 6 (fig. \ref{fig:costSemiSup2})}
    \label{fig:costSemiSup12}
\end{figure}

\textbf{miss the evolution of the Lp for the 25 scenes, estimate and exact + 2/3 scenes to see the evolution during the 30 seconds of the scenes ?}

\section{Conclusion}
\footnotesize
\bibliographystyle{unsrt}
\bibliography{bibliographie_applied}

\end{document}
